\BOOKMARK [0][-]{chapter.1}{Introduzione al problema}{}% 1
\BOOKMARK [0][-]{chapter.2}{Tecnologie e Tools per lo sviluppo}{}% 2
\BOOKMARK [1][-]{section.2.1}{Unity}{chapter.2}% 3
\BOOKMARK [2][-]{subsection.2.1.1}{Funzionamento di base}{section.2.1}% 4
\BOOKMARK [2][-]{subsection.2.1.2}{I Components}{section.2.1}% 5
\BOOKMARK [2][-]{subsection.2.1.3}{Classi necessarie per lo sviluppo}{section.2.1}% 6
\BOOKMARK [1][-]{section.2.2}{Il tool ProBuilder}{chapter.2}% 7
\BOOKMARK [1][-]{section.2.3}{Anaconda}{chapter.2}% 8
\BOOKMARK [1][-]{section.2.4}{Altri tools}{chapter.2}% 9
\BOOKMARK [0][-]{chapter.3}{Il Reinforcement learning}{}% 10
\BOOKMARK [1][-]{section.3.1}{Il sistema di ricompensa}{chapter.3}% 11
\BOOKMARK [1][-]{section.3.2}{Formalizzazione del modello}{chapter.3}% 12
\BOOKMARK [2][-]{subsection.3.2.1}{Le reward \(ricompense\)}{section.3.2}% 13
\BOOKMARK [2][-]{subsection.3.2.2}{Definizione di trajectory}{section.3.2}% 14
\BOOKMARK [2][-]{subsection.3.2.3}{Probabilit\340 delle transizioni}{section.3.2}% 15
\BOOKMARK [2][-]{subsection.3.2.4}{Le policy}{section.3.2}% 16
\BOOKMARK [2][-]{subsection.3.2.5}{Ritorno atteso e fattore di sconto}{section.3.2}% 17
\BOOKMARK [2][-]{subsection.3.2.6}{Value function}{section.3.2}% 18
\BOOKMARK [2][-]{subsection.3.2.7}{Policy ottimali}{section.3.2}% 19
\BOOKMARK [2][-]{subsection.3.2.8}{Equazione di Bellman}{section.3.2}% 20
\BOOKMARK [0][-]{chapter.4}{Q-Learning}{}% 21
\BOOKMARK [1][-]{section.4.1}{Iterazione per valore}{chapter.4}% 22
\BOOKMARK [1][-]{section.4.2}{Exploration ed Exploitation}{chapter.4}% 23
\BOOKMARK [1][-]{section.4.3}{Aggiornamento della Q-table}{chapter.4}% 24
\BOOKMARK [1][-]{section.4.4}{Episodi}{chapter.4}% 25
\BOOKMARK [1][-]{section.4.5}{Applicazione del modello al problema}{chapter.4}% 26
\BOOKMARK [1][-]{section.4.6}{Risultati}{chapter.4}% 27
\BOOKMARK [0][-]{chapter.5}{Deep Q-Learning}{}% 28
\BOOKMARK [1][-]{section.5.1}{La rete deep}{chapter.5}% 29
\BOOKMARK [2][-]{subsection.5.1.1}{Apprendimento}{section.5.1}% 30
\BOOKMARK [1][-]{section.5.2}{Experience replay}{chapter.5}% 31
\BOOKMARK [1][-]{section.5.3}{Algoritmo: Deep Q-Learning con experience replay}{chapter.5}% 32
\BOOKMARK [1][-]{section.5.4}{Versione senza cnn}{chapter.5}% 33
\BOOKMARK [1][-]{section.5.5}{Risultati ottenuti}{chapter.5}% 34
